spark-config {
  "spark.app.name": "ConformedModelFramework"
  "spark.hadoop.hbase.security.authentication": "kerberos"
  "spark.yarn.security.credentials.hbase.enabled": "true"
  "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
  "spark.yarn.maxAppAttempts": 1
  "spark.yarn.am.attemptFailuresValidityInterval": "300s"
  "spark.hadoop.fs.hdfs.impl.disable.cache": "true"

  "spark.sql.extensions": "io.delta.sql.DeltaSparkSessionExtension"
  "spark.sql.catalog.spark_catalog": "org.apache.spark.sql.delta.catalog.DeltaCatalog"
}

hbase {
  source.files: [
    "/etc/hadoop/conf/hdfs-site.xml",
    "/etc/hadoop/conf/core-site.xml",
    "/etc/hive/conf/hive-site.xml",
    "/etc/hbase/conf/hbase-site.xml"
  ]
  zookeeper.quorum: "myserver1,myserver2,myserver3"
  //metastore.table: "ns:metastore"  define table under metastore
  //metastore.cf: "meta"             define cf under metastore
}

metastore {
  // type can be - hbase or delta
  type: "delta"
  table: "/FileStore/metastore/dpf"
}

//optional - used only to use databricks mount point and secrets
s3 {
    access.key.scope: "aws"
    access.key.token: "access_key"
    secret.access.key.scope: "aws"
    secret.access.key.token: "secret_access_key"
}

source {
 project.name: "ConformedModelFramework"
 incremental.flag: false
  mapping: [
   {
      "index": 1
      "id": "trails"
      "source": "s3"
      "location": "/cignacmbucket/Sample"
      "format": "delta"
      "stream": false
      //"where": "use_hike = 1"
      "columns": ["*"]
      "distinct": true
      "join": " trails "
    }
  ],
  add.columns: [
    ["update_ts", "current_timestamp"]
  ]
}


target {
  place: "s3"
  options: {
    location: "/cignacmbucket/Sample1"
    format: "delta"
    compression: "snappy"
    //mode can be - append/overwrite/upsert/merge/logicalDelete
    //mode upsert/merge/delete applicable only for- format: "delta"
    mode: "merge"
    stream: false
    streamCheckpointLocation: ""
    delta: {
        //upsert/merge/delete applicable only for- format: "delta"
        //when match found update selected column(s), when no match found insert the row
        merge: {
            //condition: "target.column1 = source.column1 and target.column2 = source.column2"
            //set: "target.column5 = source.column5 and target.column6 = source.column6"
            condition: "target.FID = source.FID and target.trail_name = source.trail_name"
            set: "target.use_hike = 2 and target.update_ts = source.update_ts"
        }
    }
  }
}

